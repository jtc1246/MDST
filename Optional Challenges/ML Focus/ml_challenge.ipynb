{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Challenge (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, test, optimize, and analyze the performance of a classification model using a methodology of your choice for the randomly generated moons dataset.\n",
    "\n",
    "You are not being evaluated for the performance of your model. Instead, we are interested in whether you can implement a simple but rigorous ML workflow.\n",
    "\n",
    "Show all of your work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you are free to use any package you deem fit\n",
    "\n",
    "import torch\n",
    "from torch import nn, float64\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from math import floor, ceil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, Y = make_moons(random_state=42, n_samples=(50, 450), noise=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)\n",
    "# print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X))\n",
    "# print(len(Y))\n",
    "# print(type(X))\n",
    "# print(type(Y))\n",
    "# print(X.dtype)\n",
    "# print(Y.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.2\n",
    "\n",
    "num = len(X)\n",
    "test = []\n",
    "while (len(test) < TEST_RATIO * num):\n",
    "    a = randint(0, num - 1)\n",
    "    if (a not in test):\n",
    "        test.append(a)\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "test_X = []\n",
    "test_Y = []\n",
    "\n",
    "for i in range(0, num):\n",
    "    if (i in test):\n",
    "        test_X.append(X[i])\n",
    "        test_Y.append(Y[i])\n",
    "    else:\n",
    "        train_X.append(X[i])\n",
    "        train_Y.append(Y[i])\n",
    "\n",
    "train_X = np.array(train_X, dtype=np.float64)\n",
    "train_Y = np.array(train_Y, dtype=np.float64)\n",
    "test_X = np.array(test_X, dtype=np.float64)\n",
    "test_Y = np.array(test_Y, dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, num: int, _X, _Y):\n",
    "        self.num = num\n",
    "        self.X = _X\n",
    "        self.Y = _Y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index].reshape(1, 1, 2)\n",
    "        y = self.Y[index].reshape(1)\n",
    "        return (torch.from_numpy(x), torch.tensor(y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataSet(ceil(num - TEST_RATIO * num), train_X, train_Y)\n",
    "test_set = DataSet(floor(TEST_RATIO * num), test_X, test_Y)\n",
    "train_loader = DataLoader(train_set, batch_size=5, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Reshape, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.transpose(-1, -2)\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'new_shape={}'.format(\n",
    "            self.shape\n",
    "        )\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    # 输入 1 * 2, 输出一个数\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            Reshape(),\n",
    "            nn.Linear(1, 10),\n",
    "            nn.ReLU(),\n",
    "            Reshape(),\n",
    "            nn.Linear(2, 15),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1, 3, (3, 3), padding=1, padding_mode='zeros'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(3, 3, (5, 5), padding=2, padding_mode='zeros'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(450, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "loss_fn = nn.BCELoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "for epoch in range(0, 200):\n",
    "    # print(epoch, \": \", end='')\n",
    "    all_loss = 0\n",
    "    zero_loss = 0\n",
    "    for data in train_loader:\n",
    "        x, y = data\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        all_loss += loss\n",
    "    # print(all_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing / Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "for data in test_loader:\n",
    "    x, y = data\n",
    "    output = model(x)\n",
    "    # print(output[0][0],y[0][0])\n",
    "    result = 0\n",
    "    if (output[0][0] > 0.5):\n",
    "        result = 1\n",
    "    if (abs(result - y[0][0]) < 0.01):\n",
    "        correct_num += 1\n",
    "print(correct_num / (num * TEST_RATIO))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have run the above code 10 continuous times. The correctness of each time is: 0.97, 0.95, 0.96, 0.94, 0.98, 0.97, 0.98, 0.98, 0.98, 0.96. The average is 96.7%, which is higher than the correctness of all guessing 1 (0.9). Therefore, I think this model can perform well in classifying these data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78b6b4158d8f577a77be3bef6c4f5889b406541923fa59adc2e6c48950512fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
